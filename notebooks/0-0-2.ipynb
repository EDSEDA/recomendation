{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:09:00.356264Z",
     "start_time": "2024-04-15T23:08:57.934465Z"
    }
   },
   "source": [
    "import pickle\n",
    "import sys\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import torch\n",
    "from spotlight.interactions import Interactions\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.evaluation import precision_recall_score\n",
    "\n",
    "sys.path.insert(0, '..')  # Важно чтобы работали импорты из корня репозитория как в инференсе\n",
    "\n",
    "# Вместо sklearn.show_versions() мы можем проверить версии других библиотек\n",
    "print(torch.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n",
      "2.2.2\n",
      "1.26.4\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:09:19.558524Z",
     "start_time": "2024-04-15T23:09:00.357259Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "import numpy as np\n",
    "from spotlight.interactions import Interactions\n",
    "\n",
    "data_path = '../data'\n",
    "dataset_path = path.join(data_path, 'instacart-market-basket-analysis')\n",
    "\n",
    "# Загружаем данные\n",
    "raw_orders = pd.read_csv(path.join(dataset_path, 'orders.csv'))\n",
    "raw_products = pd.read_csv(path.join(dataset_path, 'products.csv'))\n",
    "raw_order_products = pd.concat([\n",
    "    pd.read_csv(path.join(dataset_path, 'order_products__prior.csv')),\n",
    "    pd.read_csv(path.join(dataset_path, 'order_products__train.csv'))\n",
    "])\n",
    "\n",
    "# Смотрим заказы одного пользователя для примера\n",
    "print(raw_orders[(raw_orders[\"user_id\"] == 1)].sort_values([\"order_number\"]))\n",
    "\n",
    "# Получаем топ-20 популярных продуктов\n",
    "top_popular_product_counts = raw_order_products.groupby('product_id').size().sort_values()[-2500:].rename('count').reset_index()\n",
    "products = top_popular_product_counts.merge(raw_products, on='product_id')\n",
    "order_products = products[['product_id']].merge(raw_order_products, on='product_id')\n",
    "orders = raw_orders[raw_orders['order_id'].isin(order_products['order_id'].unique())]\n",
    "\n",
    "# Создаем маппинги\n",
    "user_id_mapping = {user_id: i for i, user_id in enumerate(orders['user_id'].unique())}\n",
    "product_id_mapping = {product_id: i for i, product_id in enumerate(products['product_id'].unique())}\n",
    "\n",
    "# Преобразовываем user_id и product_id с использованием маппинга\n",
    "grouped_data = orders.merge(order_products, on='order_id').groupby(['user_id', 'product_id']).size()\n",
    "grouped_data = grouped_data.to_frame().reset_index().rename(columns={0: 'weight'})\n",
    "grouped_data['user_id'] = grouped_data['user_id'].map(user_id_mapping)\n",
    "grouped_data['product_id'] = grouped_data['product_id'].map(product_id_mapping)\n",
    "\n",
    "# Создаем объект Interactions с весами\n",
    "user_ids = np.array(grouped_data['user_id'], dtype=np.int32)\n",
    "product_ids = np.array(grouped_data['product_id'], dtype=np.int32)\n",
    "weights = np.array(grouped_data['weight'], dtype=np.float32)\n",
    "timestamps = np.zeros(len(user_ids), dtype=np.int32)  # Подставляем заглушку для timestamps\n",
    "\n",
    "interactions = Interactions(user_ids, product_ids, timestamps, weights)\n",
    "\n",
    "# Проверка\n",
    "print(f'Number of unique users: {len(np.unique(user_ids))}')\n",
    "print(f'Number of unique items: {len(np.unique(product_ids))}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
      "0    2539329        1    prior             1          2                  8   \n",
      "1    2398795        1    prior             2          3                  7   \n",
      "2     473747        1    prior             3          3                 12   \n",
      "3    2254736        1    prior             4          4                  7   \n",
      "4     431534        1    prior             5          4                 15   \n",
      "5    3367565        1    prior             6          2                  7   \n",
      "6     550135        1    prior             7          1                  9   \n",
      "7    3108588        1    prior             8          1                 14   \n",
      "8    2295261        1    prior             9          1                 16   \n",
      "9    2550362        1    prior            10          4                  8   \n",
      "10   1187899        1    train            11          4                  8   \n",
      "\n",
      "    days_since_prior_order  \n",
      "0                      NaN  \n",
      "1                     15.0  \n",
      "2                     21.0  \n",
      "3                     29.0  \n",
      "4                     28.0  \n",
      "5                     19.0  \n",
      "6                     20.0  \n",
      "7                     14.0  \n",
      "8                      0.0  \n",
      "9                     30.0  \n",
      "10                    14.0  \n",
      "Number of unique users: 205821\n",
      "Number of unique items: 2500\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:13:29.997907Z",
     "start_time": "2024-04-15T23:09:19.559503Z"
    }
   },
   "source": [
    "import torch\n",
    "from spotlight.factorization.explicit import ExplicitFactorizationModel\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.evaluation import precision_recall_score\n",
    "import numpy as np\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "def evaluate_model(model, interactions, test_percentage=0.2, random_state=None):\n",
    "    random_state = np.random.RandomState(random_state)\n",
    "    train, test = random_train_test_split(interactions, test_percentage=test_percentage, random_state=random_state)\n",
    "    train_mrr, test_mrr = precision_recall_score(model, train, test, k=5)\n",
    "\n",
    "    print(f\"Precision@K:\")\n",
    "    print(f\"\\t- train: {train_mrr[0].mean():.3f}\")\n",
    "    print(f\"\\t- test: {test_mrr[0].mean():.3f}\")\n",
    "\n",
    "def objective(trial):\n",
    "    random_state = np.random.RandomState(42)\n",
    "    train, test = random_train_test_split(interactions, test_percentage=0.2, random_state=random_state)\n",
    "\n",
    "    # Define parameters\n",
    "    param = {\n",
    "        'embedding_dim': trial.suggest_int(\"embedding_dim\", 5, 64),\n",
    "        'n_iter': trial.suggest_int(\"n_iter\", 1, 2),\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.001, 1),\n",
    "        'l2': trial.suggest_float(\"l2\", 1e-10, 1e-06, log=True)\n",
    "    }\n",
    "\n",
    "    # Create model\n",
    "    model = ImplicitFactorizationModel(loss='bpr', **param)\n",
    "    model.fit(train, verbose=True)\n",
    "\n",
    "    # Evaluate model\n",
    "    test_precision, test_recall = precision_recall_score(model, train, test, k=5)\n",
    "    val_precision = test_precision.mean()\n",
    "\n",
    "    return val_precision\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=1)\n",
    "# \n",
    "# best_params = study.best_params\n",
    "# for k, v in best_params.items():\n",
    "#     print(k, \":\", v)\n",
    "# \n",
    "\n",
    "best_params = {\n",
    "    'embedding_dim': 9,\n",
    "    'n_iter': 1,\n",
    "    'learning_rate': 0.01,\n",
    "    'l2': 1e-08,\n",
    "}\n",
    "\n",
    "# Train the final model\n",
    "final_model = ImplicitFactorizationModel(loss='bpr', **best_params)\n",
    "final_model.fit(interactions, verbose=True)\n",
    "\n",
    "# Evaluate the final model\n",
    "evaluate_model(final_model, interactions)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 0.23196373832925865\n",
      "Precision@K:\n",
      "\t- train: 0.400\n",
      "\t- test: 0.125\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T23:15:34.026976Z",
     "start_time": "2024-04-15T23:15:32.805502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from spotlight.cross_validation import random_train_test_split\n",
    "\n",
    "\n",
    "# Класс Model\n",
    "class Model:\n",
    "    def __init__(self, model, interactions, user_mappings, product_mappings):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model\n",
    "        self.user_mappings = user_mappings\n",
    "        self.product_mappings = product_mappings\n",
    "        self.internal_user_ids = list(user_mappings.values())\n",
    "        self.internal_product_ids = list(product_mappings.values())\n",
    "        self.inv_product_mappings = {v: k for k, v in product_mappings.items()}\n",
    "        self.rng = np.random.default_rng()\n",
    "\n",
    "    def get_recommendations(self):\n",
    "        print(f\"Model initialized on device: {self.device}\")\n",
    "        similar_user_id = int(self.rng.choice(self.internal_user_ids))\n",
    "\n",
    "        # Assuming predict method expects tensors already on the correct device\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model.predict(similar_user_id, np.array(self.internal_product_ids))  # Adjust according to actual method signature\n",
    "\n",
    "        top_indices = np.argsort(prediction)[-1:-6:-1]  # Top 5 recommendations\n",
    "        top_product_ids = [self.inv_product_mappings[idx] for idx in top_indices]\n",
    "\n",
    "        return top_product_ids\n",
    "\n",
    "# Пример использования нового класса Model\n",
    "user_mappings = {user_id: i for i, user_id in enumerate(np.unique(user_ids))}\n",
    "product_mappings = {product_id: i for i, product_id in enumerate(np.unique(product_ids))}\n",
    "recs_model = Model(final_model, interactions, user_mappings, product_mappings)\n",
    "recs_model.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "recs_product_ids = recs_model.get_recommendations()\n",
    "recs = products[products['product_id'].isin(recs_product_ids)]\n",
    "print(recs)\n",
    "\n",
    "# Сериализация модели\n",
    "import pickle\n",
    "with open('../recommendation/0-0-3.pickle', 'wb') as file:\n",
    "    pickle.dump(recs_model, file, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on device: cuda\n",
      "Empty DataFrame\n",
      "Columns: [product_id, count, product_name, aisle_id, department_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
